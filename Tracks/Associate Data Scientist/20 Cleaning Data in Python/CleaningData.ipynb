{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c308c8-5a77-419b-9f0c-a5f10d88ca95",
   "metadata": {},
   "source": [
    "## Cleaning data in Python\n",
    "\n",
    "+ Using `assert` statements to verify data quality\n",
    "+ Some data might appear to be numeric but actually be categorical\n",
    "  + e.g. `marriage_status`: 0 = never married, 1 = married, 2 = separated, 3 = divorced\n",
    "  + used `.astype('category')` as described in the **Working with Categorical Data in Python** course.\n",
    "  + after using `.astype('category')` on a categorical column, running `describe()` will make more sense (better alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be015f0-e458-4140-992a-fa080d4dcd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>duration</th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12 minutes</td>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>323</td>\n",
       "      <td>Broadway at Kearny</td>\n",
       "      <td>5480</td>\n",
       "      <td>2</td>\n",
       "      <td>1959</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24 minutes</td>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>5193</td>\n",
       "      <td>2</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8 minutes</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>23</td>\n",
       "      <td>The Embarcadero at Steuart St</td>\n",
       "      <td>3652</td>\n",
       "      <td>3</td>\n",
       "      <td>1993</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4 minutes</td>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>28</td>\n",
       "      <td>The Embarcadero at Bryant St</td>\n",
       "      <td>1883</td>\n",
       "      <td>1</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11 minutes</td>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>350</td>\n",
       "      <td>8th St at Brannan St</td>\n",
       "      <td>4626</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    duration  station_A_id  \\\n",
       "0           0  12 minutes            81   \n",
       "1           1  24 minutes             3   \n",
       "2           2   8 minutes            67   \n",
       "3           3   4 minutes            16   \n",
       "4           4  11 minutes            22   \n",
       "\n",
       "                                      station_A_name  station_B_id  \\\n",
       "0                                 Berry St at 4th St           323   \n",
       "1       Powell St BART Station (Market St at 4th St)           118   \n",
       "2  San Francisco Caltrain Station 2  (Townsend St...            23   \n",
       "3                            Steuart St at Market St            28   \n",
       "4                              Howard St at Beale St           350   \n",
       "\n",
       "                    station_B_name  bike_id  user_type  user_birth_year  \\\n",
       "0               Broadway at Kearny     5480          2             1959   \n",
       "1  Eureka Valley Recreation Center     5193          2             1965   \n",
       "2    The Embarcadero at Steuart St     3652          3             1993   \n",
       "3     The Embarcadero at Bryant St     1883          1             1979   \n",
       "4             8th St at Brannan St     4626          2             1994   \n",
       "\n",
       "  user_gender  \n",
       "0        Male  \n",
       "1        Male  \n",
       "2        Male  \n",
       "3        Male  \n",
       "4        Male  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ride_sharing = pd.read_csv('./data/ride_sharing_new.csv')\n",
    "df_ride_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17568b11-e9ad-4d27-a5eb-13363fa6c41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25760 entries, 0 to 25759\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       25760 non-null  int64 \n",
      " 1   duration         25760 non-null  object\n",
      " 2   station_A_id     25760 non-null  int64 \n",
      " 3   station_A_name   25760 non-null  object\n",
      " 4   station_B_id     25760 non-null  int64 \n",
      " 5   station_B_name   25760 non-null  object\n",
      " 6   bike_id          25760 non-null  int64 \n",
      " 7   user_type        25760 non-null  int64 \n",
      " 8   user_birth_year  25760 non-null  int64 \n",
      " 9   user_gender      25760 non-null  object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 2.0+ MB\n",
      "None \n",
      "\n",
      "count    25760.000000\n",
      "mean         2.008385\n",
      "std          0.704541\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          3.000000\n",
      "Name: user_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the information of ride_sharing\n",
    "print(df_ride_sharing.info(), \"\\n\")\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(df_ride_sharing['user_type'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d923e4a-8b5c-45b1-92b5-3c8bba22cc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25760 entries, 0 to 25759\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       25760 non-null  int64 \n",
      " 1   duration         25760 non-null  object\n",
      " 2   station_A_id     25760 non-null  int64 \n",
      " 3   station_A_name   25760 non-null  object\n",
      " 4   station_B_id     25760 non-null  int64 \n",
      " 5   station_B_name   25760 non-null  object\n",
      " 6   bike_id          25760 non-null  int64 \n",
      " 7   user_type        25760 non-null  int64 \n",
      " 8   user_birth_year  25760 non-null  int64 \n",
      " 9   user_gender      25760 non-null  object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 2.0+ MB\n",
      "None \n",
      "\n",
      "count    25760.000000\n",
      "mean         2.008385\n",
      "std          0.704541\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          3.000000\n",
      "Name: user_type, dtype: float64 \n",
      "\n",
      "count     25760\n",
      "unique        3\n",
      "top           2\n",
      "freq      12972\n",
      "Name: user_type_cat, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the information of ride_sharing\n",
    "print(df_ride_sharing.info(), \"\\n\")\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(df_ride_sharing['user_type'].describe(), \"\\n\")\n",
    "\n",
    "# Convert user_type from integer to category\n",
    "df_ride_sharing['user_type_cat'] = df_ride_sharing['user_type'].astype('category')\n",
    "\n",
    "# Write an assert statement confirming the change\n",
    "assert df_ride_sharing['user_type_cat'].dtype == 'category'\n",
    "\n",
    "# Print new summary statistics \n",
    "print(df_ride_sharing['user_type_cat'].describe(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3311b5-613e-436e-abd4-3676c9d5b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip duration of minutes\n",
    "df_ride_sharing['duration_trim'] = df_ride_sharing['duration'].str.strip('minutes')\n",
    "\n",
    "# Convert duration to integer\n",
    "df_ride_sharing['duration_time'] = df_ride_sharing['duration_trim'].astype(int)\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert df_ride_sharing['duration_time'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d483162-8262-4baf-985a-3080083ea563",
   "metadata": {},
   "source": [
    "## Data range constraints\n",
    "\n",
    "+ To follow along with the lectures, the `tire_size` and `ride_date` columns needed to be added to the data\n",
    "  + The code to add these columns is commented out because they only needed to be run once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9581db64-3624-4ce2-b9dd-2e697010123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25760, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'duration', 'station_A_id', 'station_A_name',\n",
       "       'station_B_id', 'station_B_name', 'bike_id', 'user_type',\n",
       "       'user_birth_year', 'user_gender', 'user_type_cat', 'duration_trim',\n",
       "       'duration_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_ride_sharing.shape)\n",
    "df_ride_sharing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6165f63-6258-4f30-aae6-b6767b21c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# # add a tire_sizes column (because it doesn't exist in the original data) to illustrate\n",
    "# tire_sizes = [26, 27, 29]\n",
    "# tire_size_probabilities = 100 * np.array([0.485, 0.313, 0.202])  # these were the proportions found on the execise data\n",
    "# df_ride_sharing['tire_sizes'] = random.choices(tire_sizes, weights=tuple(tire_size_probabilities), k=df_ride_sharing.shape[0])\n",
    "# # check that values follow specified distribution\n",
    "# df_ride_sharing['tire_sizes'].value_counts(normalize=True)  # looks good:\n",
    "# tire_sizes\n",
    "# 26    0.487189\n",
    "# 27    0.314946\n",
    "# 29    0.197865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9380b1-730a-4e72-af5b-1fb93aaaede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df with new column added\n",
    "# df_ride_sharing.to_csv('./data/ride_sharing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f93164f-5211-4452-b832-cbb1f7aed9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     25760\n",
      "unique        2\n",
      "top          27\n",
      "freq      13210\n",
      "Name: tire_sizes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# re-read the ride sharing data file with the new column\n",
    "df_ride_sharing = pd.read_csv('./data/ride_sharing.csv')\n",
    "\n",
    "# Convert tire_sizes to integer\n",
    "df_ride_sharing['tire_sizes'] = df_ride_sharing['tire_sizes'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "df_ride_sharing.loc[df_ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "df_ride_sharing['tire_sizes'] = df_ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(df_ride_sharing['tire_sizes'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bad0f9b-3fb8-470e-be72-d7487426779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# generate random dates between 5 years ago and 1 year into the future\n",
    "# which is roughly what the exercise data was found to be\n",
    "# rand_dates = []\n",
    "# today_date = dt.date.today()\n",
    "# for date_row in range(df_ride_sharing.shape[0]):\n",
    "#     # https://stackoverflow.com/questions/553303/how-to-generate-a-random-date-between-two-other-dates#61383231\n",
    "#     rand_delta = random.randint(-5*365, 365)\n",
    "#     rand_date = today_date + dt.timedelta(days=rand_delta)\n",
    "#     rand_dates.append(rand_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# df_ride_sharing['ride_date'] = rand_dates\n",
    "# print(df_ride_sharing['ride_date'].iloc[:11])  # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e19f5414-a1fb-4b59-978a-d7c23e4050dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df with new column added\n",
    "# df_ride_sharing.to_csv('./data/ride_sharing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c233e5-e60f-4336-96a3-42ed8edf5705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-02\n"
     ]
    }
   ],
   "source": [
    "# Convert ride_date to date\n",
    "df_ride_sharing['ride_dt'] = pd.to_datetime(df_ride_sharing['ride_date']).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "df_ride_sharing.loc[df_ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(df_ride_sharing['ride_dt'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35991a79-a46f-449d-ba71-8b615cf1747e",
   "metadata": {},
   "source": [
    "## Uniqueness contraints - dealing with duplicates\n",
    "\n",
    "+ **TODO** need to add `ride_id` column to test code in next 2 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29febeb3-3c29-4df9-a054-584eeb13424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "# duplicates = ride_sharing.duplicated(['ride_id'], keep=False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "# duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "# print(duplicated_rides[['ride_id','duration','user_birth_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e93616-b199-441f-8c8b-180841d648e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ride_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m statistics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_birth_year\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Group by ride_id and compute new statistics\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m ride_unique \u001b[38;5;241m=\u001b[39m \u001b[43mride_dup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mride_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39magg(statistics)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Find duplicated values again\u001b[39;00m\n\u001b[0;32m     11\u001b[0m duplicates \u001b[38;5;241m=\u001b[39m ride_unique\u001b[38;5;241m.\u001b[39mduplicated(subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mride_id\u001b[39m\u001b[38;5;124m'\u001b[39m, keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\VirtualEnvironments\\datacamp\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\VirtualEnvironments\\datacamp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mC:\\VirtualEnvironments\\datacamp\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ride_id'"
     ]
    }
   ],
   "source": [
    "# Drop complete duplicates from ride_sharing\n",
    "# ride_dup = df_ride_sharing.drop_duplicates(inplace=False)\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "# statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "# ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "# duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "# duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "# assert duplicated_rides.shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db874ff5-a4f0-4f55-ab7c-991922818892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453aab0-fa5f-496c-91cc-64b1d6d63fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aae88d-5981-4c61-b2c1-db56d5e1e332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c63d91-289f-4d4d-b097-0674a92df962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a9b78-c98d-4721-8af2-0f84bd0962d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb63a94-2243-48ba-8c24-8e791e090534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
